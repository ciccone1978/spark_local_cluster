services:
  spark-master:
    build: .
    image: custom-spark-image
    container_name: spark-master
    hostname: spark-master
    ports:
      - "8080:8080"  # Spark Master UI
      - "7077:7077"  # Spark Master RPC
    networks:
      - spark-network
    volumes:
      - ./workspace:/opt/bitnami/spark/workspace
    environment:
      - SPARK_MODE=master
      - SPARK_DAEMON_USER=root
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no

  spark-worker-1:
    build: .
    image: custom-spark-image
    container_name: spark-worker-1
    hostname: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"  # Spark Worker 1 UI
    networks:
      - spark-network
    volumes:
      - ./workspace:/opt/bitnami/spark/workspace
    working_dir: /opt/bitnami/spark/workspace
    environment:
      - SPARK_MODE=worker
      - SPARK_DAEMON_USER=root
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=4G
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no

  spark-worker-2:
    build: .
    image: custom-spark-image
    container_name: spark-worker-2
    hostname: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"  # Spark Worker 2 UI
    networks:
      - spark-network
    volumes:
      - ./workspace:/opt/bitnami/spark/workspace
    working_dir: /opt/bitnami/spark/workspace
    environment:
      - SPARK_MODE=worker
      - SPARK_DAEMON_USER=root
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=4G
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no

  jupyterlab:
    build: .
    image: custom-spark-image
    container_name: jupyterlab
    hostname: jupyterlab
    depends_on:
      - spark-master
    ports:
      - "8888:8888" # JupyterLab UI
      - "4040:4040" # Spark UI for Jupyter
    networks:
      - spark-network
    volumes:
      - ./workspace:/opt/bitnami/spark/workspace
    working_dir: /opt/bitnami/spark/workspace  
    env_file:
      - .env
    environment:
      - SPARK_MODE=client
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
    command: >
      sleep infinity

  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"  # S3 API Port
      - "9001:9001"  # MinIO Console UI Port
    networks:
      - spark-network
    volumes:
      # This is where MinIO will store its data on your host machine
      - ./storageS3:/data
    environment:
      - MINIO_ROOT_USER=${MINIO_USER}
      - MINIO_ROOT_PASSWORD=${MINIO_PASSWORD}
    command: server /data --console-address ":9001"    

  postgres:
    image: postgis/postgis:17-3.5
    container_name: postgres-gis
    hostname: postgres-gis
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    networks:
      - spark-network

volumes:
  postgres_data:

networks:
  spark-network:
    driver: bridge
